\documentclass[11pt,a4paper,sans]{moderncv}

% ModernCV themes
\moderncvstyle{classic}
\moderncvcolor{blue}

% Character encoding
\usepackage[utf8]{inputenc}

% Adjust the page margins
\usepackage[scale=0.9]{geometry}
\usepackage{needspace}

% Personal data
\firstname{Florian}
\familyname{Valade}
\title{Ingénieur de Recherche en Machine Learning}
\address{France}{}
\phone[mobile]{+33 6 17 57 19 12}
\email{florian\_val@outlook.fr}
\homepage{fvalade.fr}
\social[linkedin]{florian-valade}
\social[github]{FlorianVal}

\begin{document}
\makecvtitle

% PROFILE
\section{Profil}
Ingénieur de Recherche en Machine Learning spécialisé dans l'apprentissage profond efficace, les grands modèles de langage (LLMs), l'inférence adaptative et l'entraînement distribué. Expérimenté dans la conception de nouvelles architectures, l'exécution d'expériences à grande échelle, la construction de systèmes multimodaux et l'optimisation de l'infrastructure d'entraînement sur GPU.

% HIGHLIGHTS
\section{Sélection de Recherches et Réalisations}
\cvlistitem{Entraînement et fine-tuning de LLMs type GPT (70M--1.3B paramètres) sur clusters multi-GPU (V100/A100) avec FSDP, DDP, Accelerate et pipelines distribués personnalisés.}
\cvlistitem{Développement de méthodes d'inférence adaptative (sorties anticipées, option de rejet, récursion) réalisant des réductions significatives de FLOPs tout en préservant la précision du modèle.}
\cvlistitem{Construction de pipelines de données à grande échelle : chargeurs streaming, déduplication, filtrage et curation.}
\cvlistitem{Conception de variantes de Transformers efficaces en calcul et analyse des lois de mise à l'échelle sur les compromis perte--calcul.}
\cvlistitem{Développement d'outils internes basés sur LLM pour l'automatisation des workflows.}
\cvlistitem{Gestion de serveurs GPU et infrastructure de recherche ; optimisation du débit, stabilité d'entraînement et reproductibilité.}

% EDUCATION
\section{Formation}
\cventry{2022--Présent}{Doctorat en Efficacité des Algorithmes d'Apprentissage Profond}{Université Gustave Eiffel}{Paris, France}{}{}
\cventry{2021}{Master en Informatique, Big Data et Apprentissage Automatique}{ECE Paris}{Paris, France}{}{}
\cventry{2015}{Baccalauréat Scientifique}{Lycée L'Espérance}{Paris, France}{}{}

% PUBLICATIONS
\section{Publications}
\cvitem{2025}{\textbf{EERO: Early Exit with Reject Option} --- UAI 2025.
    \begin{itemize}
        \item Formalise les sorties anticipées sélectives utilisant les compromis risque--couverture.
        \item Respecte des budgets de calcul stricts et améliore le compromis vitesse/précision de l'état de l'art.
    \end{itemize}}
\cvitem{2024}{\textbf{Accelerating Large Language Model Inference with Self-Supervised Early Exits}.
    \begin{itemize}
        \item Introduit des extensions de sorties anticipées fine-tunées pour LLMs utilisant des signaux de supervision internes.
        \item Permet une inférence efficace en FLOPs avec accélération jusqu'à 50\%.
        \item Atteint +66\% de taux d'acceptation et 14x moins de tokens gaspillés comparé au décodage spéculatif.
    \end{itemize}}

% EXPERIENCE
\needspace{6\baselineskip}
\section{Expérience}

\cventry{2026--Actuel}{Ingénieur de Recherche en IA}{Fujitsu}{Paris, France}{}{
    \begin{itemize}
        \item Développement et adaptation de grands modèles de langage pour diverses applications.
    \end{itemize}}

\cventry{2022--2026}{Doctorant et Ingénieur de Recherche}{Fujitsu -- Université Gustave Eiffel}{Paris, France}{}{
    \begin{itemize}
        \item Conception d'architectures d'inférence adaptative (sorties anticipées, récursion, prédiction sélective) pour modèles de vision et LLMs.
        \item Entraînement de modèles type GPT (70M--1.3B paramètres) avec FSDP, DDP, Accelerate et clusters GPU distribués.
        \item Construction de pipelines de données à grande échelle : filtrage, déduplication, scoring qualité et curation multimodale.
        \item Recherche sur les architectures efficaces en FLOPs et expériences de mise à l'échelle du calcul.
        \item Développement d'outils internes pour évaluation, comparaison de modèles, validation de datasets et visualisation.
        \item Gestion de serveurs multi-GPU et infrastructure d'entraînement.
        \item Enseignement de Vision par Ordinateur et NLP à des étudiants en Master.
    \end{itemize}}

\cventry{2021--2022}{Data Scientist}{Fujitsu}{Paris, France}{}{
    \begin{itemize}
        \item Développement et déploiement de systèmes de vision par ordinateur et d'apprentissage profond pour clients industriels.
        \item Travail sur des applications multimodales combinant vision, métadonnées et texte.
    \end{itemize}}

\cventry{2018--2021}{Apprenti Ingénieur en Vision par Ordinateur}{Fujitsu -- ECE Paris}{Paris, France}{}{
    \begin{itemize}
        \item Application de l'apprentissage profond à la détection, segmentation et systèmes embarqués.
        \item Collecte de données, prétraitement et ingénierie de pipelines.
    \end{itemize}}

\cventry{2018}{Stagiaire en Deep Learning}{Fujitsu}{Paris, France}{}{
    \begin{itemize}
        \item Développement de démonstrateurs utilisant le deep learning pour tâches de vision.
    \end{itemize}}

% SKILLS
\section{Compétences}
\cvitem{Machine Learning}{LLMs, Transformers, entraînement distribué, IA multimodale, inférence adaptative, efficacité modèle, calibration, traitement de données.}
\cvitem{Systèmes Distribués}{FSDP, DDP, Accelerate, DeepSpeed, Slurm, Docker, Kubernetes, clusters multi-GPU, profiling, monitoring.}
\cvitem{Programmation}{Python, C, C\#, Java, SQL.}
\cvitem{Frameworks}{PyTorch, TensorFlow, JAX, MLX, écosystème HuggingFace, W\&B, Git.}
\cvitem{Langues}{Anglais (Courant), Français (Natif), Espagnol (Intermédiaire).}

% PROJECTS
\section{Projets}
\cvitem{2025}{\textbf{Recursive GPT}. Projet de recherche explorant les lois de mise à l'échelle des Transformers récursifs pour réduire l'usage mémoire et améliorer l'efficacité FLOP ; développement de prototypes à couches récursives et analyse des comportements de mise à l'échelle du calcul.}
\cvitem{2023}{\textbf{Inférence Adaptative pour LLMs}. Implémentation de têtes de sorties anticipées et couches de supervision internes sur modèles type GPT. Utilisation de modèles Pythia et Phi ; fine-tuning des têtes intermédiaires ; développement d'outils d'évaluation pour compromis FLOP--perte.}
\cvitem{2022}{\textbf{FreshDetect}. Classification en temps réel de produits frais déployée via microservices conteneurisés (PyTorch, Docker).}
\cvitem{2020}{\textbf{Handterpret}. Système de détection de position de la main basé sur infrarouge utilisant capteurs embarqués.}
\cvitem{2017}{\textbf{AutoCradle}. Détection de pleurs de bébé déclenchant le balancement autonome du berceau.}

\end{document}
